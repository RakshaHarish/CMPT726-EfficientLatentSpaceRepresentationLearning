# -*- coding: utf-8 -*-
"""ConditionalVAE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19UptOH38f7_11SfTlSO97ZFZYlT-3NKO
"""

import torch, torchvision
from torch import nn
from torch.utils.data import DataLoader, Dataset, Subset
from torchvision import transforms
import torch.nn.functional as tf
import numpy as np

# ConditionalVAE = Encoder + Conditioner + Decoder
# Assumption -> Dataset = NYU data -> "nyu.mat" file as input
# img size = 216x216 = 46656 = input_dim
# Note : fully connected layers used in encoder, conditioner and decoder
# This file can be called in the "main.py" (if createdd), to integrate with dataloader, train/test code to evaluate the model performance
latent_dim = 250
hidden_dim = 400
num_classes = 2 # consider num_classes = 2, 1 for indoor scenes and the other for outdoor scenes [Extra classes can be added -> kitchen, cafe, bathroom, etc images]

class Encoder(nn.Module):
    def __init__(self):
        super(Encoder, self).__init__()
        self.fc1 = nn.Linear(46656, hidden_dim)
        self.fc21 = nn.Linear(hidden_dim, latent_dim)
        self.fc22 = nn.Linear(hidden_dim, latent_dim)
        
    def forward(self, x):
        x = nn.relu(self.fc1(x.view(-1, 46656)))
        mu = self.fc21(x)
        logvar = self.fc22(x)
        return mu, logvar

# Create the conditioner class, taking extra condition on num_classes in hidden_dim
class Conditioner(nn.Module):
  def __init__(self):
    super(Conditioner, self).__init__()
    self.fc1 = nn.Linear(num_classes, hidden_dim)
    self.fc21 = nn.Linear(hidden_dim, latent_dim)

  def forward(self, x):
    x = nn.relu(self.fc1(x))
    x = self.fc2(x)
    return torch.sigmoid(x)

class Decoder(nn.Module):
    def __init__(self):
        super(Decoder, self).__init__()
        self.fc1 = nn.Linear(latent_dim, hidden_dim)
        self.fc2 = nn.Linear(hidden_dim, 46656)
    
    def forward(self, x):
        x = nn.relu(self.fc1(x))
        x = self.fc2(x)
        return torch.sigmoid(x)

# Creates the ConditionalVAE class
class CVAE(nn.Module):
    def __init__(self):
        super(CVAE, self).__init__()
        self.encoder = Encoder()
        self.conditioner = Conditioner()
        self.decoder = Decoder()
        self.fc_mu = nn.Linear(128, hidden_dim) # mean of fc layer
        self.fc_var = nn.Linear(128, hidden_dim) # var of fc layer
        self.init_weights()
        
        if torch.cuda.is_available(): # gpu availability check
          self.cuda()

    def reparam(self, mu, logvar): 
        std = logvar.mul(0.5).exp_()
        esp = torch.randn(*mu.size()).type_as(mu)
        z = mu + std * esp
        return z

    def forward(self, x, y):
        if self.training:
            h = self.encoder(x)
            mu, logvar = self.fc_mu(h), self.fc_var(h)
            hx = self.reparam(mu, logvar)
            y_onehot = self._onehot(y)
            hy = self.conditioner(y_onehot)
            h = torch.cat([hx, hy], dim=1)
            y = self.decoder(h)
            return y, mu, logvar
        else:
            hx = self._represent(x)
            hy = self.conditioner(self._onehot(y))
            h = torch.cat([hx, hy], dim=1)
            y = self.decoder(h)
            return y

    def generate(self, y):
        hy = self.conditioner(self._onehot(y))
        hx = self._sample(y.shape[0]).type_as(hy)
        h = torch.cat([hx, hy], dim=1)
        y = self.decoder(h)
        return y

    def _represent(self, x):
        h = self.encoder(x)
        mu, logvar = self.fc_mu(h), self.fc_var(h)
        hx = self.reparam(mu, logvar)
        return hx

    def _onehot(self, y): # essential for conditioner eval
        y_onehot = torch.FloatTensor(y.shape[0], self.num_classes)
        y_onehot.zero_()
        y_onehot.scatter_(1, y, 1)
        return y_onehot
    
    def _sample(self, num_samples):
        return torch.FloatTensor(num_samples, self.hid1_dims).normal_()

    def init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                m.weight.data.normal_(0, 0.01)
                m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()
# end of CVAE class 

model = CVAE()

# Setting the optimiser
optimizer = torch.optim.Adam(model.parameters(),lr=0.001) # learning rate can be modified accordingly

# Note, loss function variation in CVAE to be re-examined
# define the loss function -> using binary_cross_entropy loss with KL divergence
def loss_function(x_hat, x, mu, logvar):  # where x = instance of training; x_hat, mu, logvar = model(x); same concept can be applied for testing phase
    BCE = nn.functional.binary_cross_entropy(x_hat, x.view(-1, 46656), reduction='sum')
    KLDiv = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2))
    return BCE + KLDiv
