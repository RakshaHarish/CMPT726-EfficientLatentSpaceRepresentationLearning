# -*- coding: utf-8 -*-
"""NYU_rgbd.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BWhDJgT7ezr1q5Tjlpz2sIArdJsu4Djv
"""

import torch, torchvision
from torch import nn
from torch.utils.data import DataLoader, Dataset, Subset
from torchvision import transforms
import torch.nn.functional as tf
import numpy as np
from matplotlib import pyplot as plt
from scipy.io import loadmat


# NYU Dataset 
# -> image is 216x216, input vector size = 46656  

class NYU_DepthDataset(Dataset):
    def __init__(self, mat_file):
      mat = loadmat(mat_file, verify_compressed_data_integrity=True)
      images = torch.from_numpy(mat['images']).permute(3, 2, 0, 1)
      depths = torch.from_numpy(mat['depths']).permute(2, 0, 1)

      images_max = images.amax((2, 3), keepdim=True) 
      images_min = images.amin((2, 3), keepdim=True) 
      images = (images - images_min) / (images_max - images_min)

      depths_max = depths.amax((1, 2), keepdim=True) 
      depths_min = depths.amin((1, 2), keepdim=True) 
      depths = (depths - depths_min) / (depths_max - depths_min)

      self.rgbd = torch.cat((images, depths.unsqueeze(1)), dim=1)

      self.std, self.mean = torch.std_mean(self.rgbd, (0, 2, 3))
      self.rgbd = transforms.functional.normalize(self.rgbd, self.mean, self.std)

    def __len__(self):
        return self.rgbd.shape[0]

    def __getitem__(self, idx):
      return self.rgbd[idx]

# Note : to be filled
batch_size = 50
kwargs = {'num_workers': 1, 'pin_memory': True}
nyu =   NYU_DepthDataset('./nyu.mat')
trainset = Subset(nyu, range(0, 1159))
testset =  Subset(nyu, range(1159, len(nyu)))
train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=batch_size, shuffle=True, **kwargs)
test_loader = torch.utils.data.DataLoader(dataset=testset, batch_size=batch_size, shuffle=True, **kwargs)

# initialize random seeds; select gpu device if available
torch.manual_seed(1)
torch.cuda.manual_seed(1) 
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# function to display the reconstructed images
# this function can be called during training/testing
def display_images(in_, out, n=1, label=None, count=False):
    for N in range(n):
        if in_ is not None:
            in_pic = in_.data.cpu().view(-1, 28, 28)
            plt.figure(figsize=(20, 4))
            plt.suptitle(label + ' â€“ reconstructed images', color='w', fontsize=20)
            for i in range(4):
                plt.subplot(1,4,i+1)
                plt.imshow(in_pic[i+4*N])
                plt.axis('off')
        out_pic = out.data.cpu().view(-1, 28, 28)
        plt.figure(figsize=(20, 6))
        for i in range(4):  
            plt.subplot(1,4,i+1)
            plt.imshow(out_pic[i+4*N])
            plt.axis('off')
            if count: plt.title(str(4 * N + i), color='w')

# creating basic VAE model for image reconstruction; depth encoding - pending

d = 10 # data points can be varied accordingly
class VAE(nn.Module):
    def __init__(self):
        super().__init__()

        self.encoder = nn.Sequential(nn.Linear(46656, d ** 2),nn.ReLU(),nn.Linear(d ** 2, d * 2))
        self.decoder = nn.Sequential(nn.Linear(d, d ** 2),nn.ReLU(),nn.Linear(d ** 2, 46656),nn.Sigmoid(),)
        
        # Note : classes for Encoder/Decoder can be added to encode depths using convolutions
        # class Encoder(nn.Module):
        # class Decoder(nn.Module):

    def reparam(self, mu, logvar):
        if self.training:
            std = logvar.mul(0.5).exp_()  # compute standard dev using non-negative logvariance
            eps = std.data.new(std.size()).normal_() # to get normal distribution for backprop in training
            return eps.mul(std).add_(mu)
        else:
            return mu

    def forward(self, x):
        mu_logvar = self.encoder(x.view(-1, 784)).view(-1, 2, d)
        mu = mu_logvar[:, 0, :]
        logvar = mu_logvar[:, 1, :]  # calculating the value of 'mu' and 'logvar' from encoder
        z = self.reparam(mu, logvar) # finding z by reparameterization
        return self.decoder(z), mu, logvar # return the decoder output

model = VAE().to(device)

# Setting the optimiser
optimizer = torch.optim.Adam(model.parameters(),lr=0.01) # learning rate can be modified accordingly

# define the loss function -> using binary_cross_entropy loss with KL divergence
def loss_function(x_hat, x, mu, logvar):  # where x = instance of training; x_hat, mu, logvar = model(x); same concept can be applied for testing phase
    BCE = nn.functional.binary_cross_entropy(x_hat, x.view(-1, 784), reduction='sum')
    KLDiv = 0.5 * torch.sum(logvar.exp() - logvar - 1 + mu.pow(2))
    return BCE + KLDiv

# Training and testing the VAE

epochs = 20
codes = dict(mu1=list(), var1=list(), y1=list())
for epoch in range(0, epochs + 1):
    # Training
    if epoch > 0:  # test untrained net first
        model.train()
        train_loss = 0
        for x, _ in train_loader:
            x = x.to(device)
            x_hat, mu, logvar = model(x)
            loss = loss_function(x_hat, x, mu, logvar)
            train_loss += loss.item()
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
       
        print(f'====> Epoch: {epoch} Train loss: {train_loss / len(train_loader.dataset):.4f}')
    
    # Testing
    means, logvars, labels = list(), list(), list()
    with torch.no_grad():
        model.eval()
        test_loss = 0
        for x, y in test_loader:
            x = x.to(device)
            x_hat, mu, logvar = model(x)
            test_loss += loss_function(x_hat, x, mu, logvar).item()
            means.append(mu.detach())
            logvars.append(logvar.detach())
            labels.append(y.detach())
     
    codes['mu1'].append(torch.cat(means))
    codes['var1'].append(torch.cat(logvars))
    codes['y1'].append(torch.cat(labels))
    test_loss /= len(test_loader.dataset)
    print(f'====> Test set loss: {test_loss:.4f}')
    display_images(x, x_hat, 1, f'Epoch {epoch}')
